# 암호화폐 가격 변동성 예측 모델

## 📑 프로젝트 개요

본 프로젝트는 암호화폐 시계열 데이터와 기술적 분석(TA) 지표만으로 딥러닝 모델이 유의미한 가격 예측을 수행할 수 있는지, 그 한계를 탐구하며 딥러닝 학습 과정 체험을 목표로 함.

프로젝트는 Transformer 기반 **PatchTST** 모델로 실험을 시작하여 **PatchTSMixer**로 전환했으며, **Optuna**를 이용한 하이퍼파라미터 튜닝 과정에서 모델이 데이터의 패턴을 효과적으로 학습하지 못한다는 구체적인 증거를 발견함.

결론적으로, 본 프로젝트는 예측 모델의 성공적인 개발을 넘어, **제한된 데이터로 딥러닝 모델을 학습시킬 때 발생하는 문제점을 명확히 식별하고, 딥러닝에 대한 학습**하는 데 의의를 둠.

## 🎯 주요 목표 및 결론

### 목표
1.  **범용 예측 모델 가능성 탐색**: 특정 암호화폐에 국한되지 않고, 업비트 시장의 모든 암호화폐에 적용 가능한 범용 가격 변동률 예측 모델 개발.
2.  **확률적 분포 예측 (Probabilistic Forecasting)**: 미래 `1일`, `3일`, `7일` 후의 가격 변동률에 대한 확률적 분포를 예측. 모델은 NLL(Negative Log-Likelihood) 손실 함수를 사용하여 학습되며, 결과는 평균 예측값과 신뢰구간으로 제시됨.
    -   **결과 형태 예시**:
        -   `Horizon: +1 day(s)`
        -   `True Value: +3.0457%`
        -   `Prediction (Mean): +10.1577%`
        -   `90% Confidence Interval: [-8.6283%, +28.9437%]`
        -   `Probability of Price Increase (>0%): 81.46%`
    -   **의사결정 배경**: 암호화폐 시장은 예측이 틀릴 가능성이 매우 높은, 극심한 불확실성을 내포함. 따라서 단일 예측값(Point-prediction)을 제시하는 것은 실용성이 떨어진다고 판단. 대신, 모델이 예측의 **'불확실성' 자체를 학습**하여 신뢰구간을 함께 제공하는 확률적 분포 예측을 목표로 설정. 이를 통해 예측이 얼마나 믿을 만한가를 평가할 수 있음.
3.  **데이터 한계성 검증**: 현실적인 비용 문제(크롤링, 데이터 저장/가공)를 고려, 기술적 분석 지표만으로 유의미한 예측이 가능한지 그 한계를 실험적으로 검증.

## 💾 데이터셋 및 전처리

-   **수집 소스**: 업비트(Upbit) Open API
-   **수집 대상**: API를 통해 조회 가능한 모든 암호화폐 (KRW 마켓)
-   **데이터 기간**: 각 암호화폐의 상장일 ~ 2025년 7월 30일
-   **주요 피처**: 시가, 고가, 저가, 종가, 거래량 및 이를 기반으로 생성된 다수의 기술적 분석 지표.
-   **데이터 스케일링**: **이상치에 강건한 `RobustScaler`를 채택**하여 데이터의 안정성을 확보함.
    -   **의사결정 배경**: `StandardScaler`는 평균과 표준편차를 사용하기 때문에 암호화폐 시장에서 빈번하게 발생하는 급등/급락과 같은 극단적인 이상치(outlier)에 스케일링 결과 왜곡 가능 반면 `RobustScaler`는 중앙값(median)과 사분위수 범위(IQR)를 사용하여 이러한 이상치의 영향을 최소화 따라서 데이터의 본질적인 분포를 더 안정적으로 유지하기 위해 `RobustScaler`를 선택.
    -   **데이터 전처리**: 단기 예측을 하되 중단기적인 패턴 예측을 위해 sequence length 60 설정

## 🤖 모델 아키텍처 및 실험 과정

1.  **PatchTST**: 초기 모델로 Patch Time Series Transformer를 사용하여 실험을 시작. 실험 과정에서 NLL(Negative Log-Likelihood) 성능이 `2.17` 이하로 개선되지 않는 한계를 관찰.
2.  **PatchTSMixer로 전환**: 더 가볍고 효율적인 구조로 알려진 PatchTSMixer 모델로 변경하여 실험을 지속.
    -   **의사결정 배경**: PatchTST의 성능 정체 후 단순히 다른 복잡한 모델을 시도하기보다 **실험의 효율성**을 높이는 방향을 고민. PatchTSMixer는 Transformer의 Self-Attention 레이어를 간단한 MLP(Multi-Layer Perceptron) 레이어로 대체하여 훨씬 가벼운 연산량 사용. 제한된 리소스 환경에서 더 많은 실험을 반복하기 위한 더 빠른 학습 및 추론 기대
3.  **Optuna 하이퍼파라미터 튜닝**:
    -   **의사결정 배경**: 파라미터를 수동으로 변경해보며 파라미터의 effect 숙지 후 완료 후 모든 실험을 수동으로 하기엔 제한이 있음을 인지.
    -   **문제 발견**: `d_model`, `batch_size`, `num_mixer_layers` 등의 파라미터가 설정된 탐색 범위의 최대치로 계속 요구됨.
    -   **한계 직면**: 파라미터 탐색 범위를 확장했으나, 로컬 PC의 성능 한계(OOM, Out of Memory) 및 과도한 예상 학습 시간(trial 당 100시간 이상)으로 튜닝 중단.
    -   **성능 정체**: PatchTSMixer의 NLL 역시 `3.1` 이하로 유의미하게 감소하지 않으며 모델이 수렴하지 못하는 현상을 재확인.

## 최종 결론
기술적 분석 지표만으로는 암호화폐 가격의 복잡한 패턴을 학습하기에 정보가 불충분함. 하이퍼파라미터 튜닝 과정에서 모델이 지속적으로 더 큰 `d_model`, `batch_size` 등을 요구하는 현상은, 주어진 데이터 내에서 명확한 신호를 찾지 못하고 있다는 강력한 증거임.

따라서 실용적인 예측 모델 구축을 위해서는 **더 큰 학습 리소스**를 확보하거나, **거시 경제 지표, 주요 뉴스, 소셜 미디어 데이터(시장 심리)와 같은 핵심적인 외부 데이터를 반드시 통합해야 함.**

## 🔬 향후 개선 방향

본 연구의 결론을 바탕으로, 다음과 같은 방향으로 프로젝트를 발전시킬 수 있음.

### 모델 학습
-   **예측 방식 변경**: 7일간의 누적 변동률을 예측하는 현재 방식 대신, `1일`, `3일`, `7일`을 각각 독립적으로 예측하는 개별 모델을 구축하여 성능 비교.
-   **문제 단순화**: `1, 3, 7일` 동시 예측이 아닌, `다음 날 하루`의 변동성 혹은 `상승 or 하락` 예측하도록 목표를 좁혀 모델이 패턴을 더 쉽게 학습하도록 유도.
-   **장기 학습**: 더 많은 Epoch과 낮은 Early Stopping `threshold`, 높은 `patience`를 설정하여 Bad Local Minima를 벗어날 가능성 탐색.
-   **튜닝 과정 분석**: `Optuna`의 시각화 기능(`plot_optimization_history`, `plot_param_importances`)을 활용하여 하이퍼파라미터 탐색 과정을 심도 있게 분석하고, 파라미터와 모델 성능 간의 관계를 파악.

### 데이터
-   **기술 지표에 대한 심도 깊은 이해**: 각 지표들의 상관관게와 의미를 파악, 가감하여 Quality In / Quality Out 유도.
-   **외부 데이터 통합**: 가장 중요한 개선점으로, 뉴스 기사, 트위터/레딧 감성 분석, 연준 금리 발표와 같은 거시 경제 지표를 피처로 추가하여 모델의 예측력을 강화.


## 📖 회고 (Retrospective)

1.  **조기 가설 검증의 중요성**: 초기 모델(PatchTST)의 성능이 정체되었을 때, 다른 모델(PatchTSMixer)로 전환하기보다 **제한된 규모의 하이퍼파라미터 튜닝을 먼저 수행**했다면 "모델 아키텍처가 아닌 데이터 자체의 정보 부족이 근본 원인"이라는 현재의 결론에 더 빠르게 도달했을 것입니다. 이는 문제의 본질을 조기에 파악하기 위한 신속한 실험 설계의 중요성을 일깨워 줍니다.

2.  **베이스라인 모델의 필요성**: 실험 초기에 `LSTM`이나 `ARIMA`와 같은 더 간단한 베이스라인 모델을 설정하지 않은 점이 아쉽습니다. 베이스라인과의 성능 비교는 복잡한 모델의 도입이 실제로 효과가 있었는지, 혹은 문제 자체가 특정 모델의 복잡성과 무관하게 어려운 것인지를 판단하는 객관적인 기준이 되었을 것입니다. 향후 프로젝트에서는 반드시 베이스라인을 먼저 구축하여 실험의 방향성과 결론의 설득력을 강화할 것입니다.

3.  **정성적 분석의 가치**: NLL 점수와 같은 정량적 지표에 더해, **예측 실패 사례에 대한 정성적 분석(Error Analysis)**이 부족했습니다. 예측 결과를 시각화하여 어떤 조건(예: 급등/급락장, 특정 자산)에서 모델이 특히 취약한지를 분석했다면, "정보 부족"이라는 결론을 뒷받침하는 더 구체적이고 직관적인 증거를 확보할 수 있었을 것입니다.

## 🛠️ 주요 의존성

-   Python 3.11
-   PyTorch
-   Transformers
-   Scikit-learn
-   Pandas
-   Optuna
-   TA-Lib
-   Hugging Face
